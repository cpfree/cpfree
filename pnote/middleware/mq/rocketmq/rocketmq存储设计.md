---
keys: 
type: copy
url: <>
id: 220211-173735
---

# rocketMq存储设计

> 参考自: <https://baijiahao.baidu.com/s?id=1716298346502205062>

## rocket MQ 内存设计简析

RocketMQ 作为一款基于磁盘存储的中间件，具有无限积压能力，并提供`高吞吐、低延迟`的服务能力，其最核心的部分必然是它优雅的存储设计。

RocketMQ 存储的文件主要包括 `Commitlog` 文件、`ConsumeQueue` 文件、`Index` 文件。

1. RocketMQ 将所有主题的消息存储在同一个文件中，确保消息发送时按顺序写文件，尽最大能力确保消息发送的高可用性与高吞吐量。

   RocketMQ 在消息写入过程中追求极致的磁盘顺序写。所有主题的消息全部写入一个文件，即 `Commitlog` 文件。所有消息按抵达顺序依次追加到文件中，消息一旦写入，不支持修改。

2. 消息中间件一般都是基于主题的订阅与发布模式，消息消费时必须按照主题进行筛选消息，显然从 `Commitlog` 文件中按照 `topic` 去筛选消息会变得及其低效.
   
   为了提高根据主题检索消息的效率，RocketMQ 引入了 `ConsumeQueue` 文件，俗称消费队列文件。

3. 关系型数据库可以按照字段属性进行记录检索，作为一款主要面向业务开发的消息中间件.

   RocketMQ 也提供了基于消息属性的检索能力，底层的核心设计理念是为 Commitlog 文件建立哈希索引，并存储在 `Index` 文件中。

在 RocketMQ 中顺序写入到 Commitlog 文件后，ConsumeQueue 与 Index 文件都是异步构建的，其数据流向图如下：

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644571681959.png)

## 详细分析

### `Commitlog` 文件

正如关系型数据会为每一条数据引入一个 ID 字段，在基于文件编程的模型中，也会为一条消息引入一个身份标志：`消息物理偏移量`，即消息存储在文件的起始位置。

正是有了物理偏移量的概念，Commitlog 的文件名命名也是极具技巧性，使用了存储在该文件的第一条消息在整个 Commitlog 文件组中的偏移量来命名，例如第一个 Commitlog 文件为 `0000000000000000000`，第二个文件为 `00000000001073741824`

- 消息查找

   给出任意一个消息的物理偏移量，例如消息偏移量为 73741824，可以通过二分法进行查找，快速定位这个文件在第一个文件中，然后用消息的物理偏移量减去该文件的名称所得到的差值，就是在该文件中的绝对地址.

### `ConsumeQueue` 文件

消息消费模型是基于主题的订阅机制，即一个消费组是消费特定主题的消息。如果根据主题从 commitlog 文件中检索消息，只能从文件的第一条消息逐条检索，其性能可想而知.

故为了解决基于 topic 的消息检索问题，RocketMQ 引入了 `consumequeue` 文件

`consumequeue` 文件是一个消息队列文件, 组织方式为 `/topic/queue`, 同时同一个队列可以存在多个文件.

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644572568412.png)


Consumequeue 的设计极具技巧，每个条目长度固定; 每个条目内容如下
   - 8 字节 `commitlog` 物理偏移量.
   - 4 字节 消息长度.
   - 8 字节 `tag hashcode`.

   每个条目长度固定, 使得可以使用访问类似数组下标的方式快速定位条目, 可以极大的提高搜索效率.

- 消费者消费消息流程

   消息消费者根据 topic、消息消费进度（consumeuqe 逻辑偏移量），即第几个 Consumeque 条目，这样的消费进度去访问消息的方法为使用逻辑偏移量 `logicOffset * 20` 即可找到该条目的起始偏移量（consumequeue 文件中的偏移量），然后读取该偏移量后 20 个字节即得到一个条目，无须遍历 `consumequeue` 文件。

> consumequeue 文件解决了基于 topic 查找的问题，但如果想基于消息的某一个属性查找消息，consumequeue 文件就无能为力了。

### `index` 文件

> RocketMQ 与 Kafka 相比具有一个强大的优势，就是支持按消息属性检索消息

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644573112279.png)

IndexFile 文件基于物理磁盘文件实现 Hash 索引。其文件内容如下

   - 40 字节的文件头
   - 500万 个 Hash 槽，每个 Hash 槽 4 个字节，
   - 2000万 个 Index 条目，每个条目由 20个 字节构成(4 字节索引 key 的 hashcode、8 字节消息物理偏移量、4 字节时间戳、4 字节的前一个 Index 条目（Hash 冲突的链表结构）)。

即 IndexFile 文件建立了索引 Key 的 hashcode 与物理偏移量的映射关系，根据 key 先快速定义到 commitlog 文件。

## 其它

rocketMQ 是如何保证写入性能的

   1. 顺序写
   2. 内存映射

### 顺序写

基于磁盘的读写，提高其写入性能的另外一个设计原理是**磁盘顺序写**。

磁盘顺序写广泛用在基于文件的存储模型中，大家不妨思考一下 MySQL Redo 日志的引入目的，我们知道在 MySQL InnoDB 的存储引擎中，会有一个内存 Pool，用来缓存磁盘的文件块，当更新语句将数据修改后，会首先在内存中进行修改，然后将变更写入到 redo 文件(刷写到磁盘)，然后定时将 InnoDB 内存池中的数据刷写到磁盘。

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644573836892.png)

为什么不一有数据变更，就直接更新到指定的数据文件中呢？

   以 MySQL InnoDB 中一个库存在上千张表，每一个张的数据会使用单独的文件存储.
   如果每一个表的数据发生变更，就刷写到磁盘，就会存在大量的随机写入，性能无法得到提升.
   故引入一个 redo 文件，顺序写 redo 文件，从表面上多了一步刷盘操作，但由于是顺序写，相比随机写，带来的性能提升是非常显著的。

### 内存映射机制

虽然基于磁盘的顺序写可以极大提高 IO 的写效率，但如果基于文件的存储采用常规的 JAVA 文件操作 API，例如 FileOutputStream 等，其性能提升会很有限，RocketMQ 引入了内存映射，将磁盘文件映射到内存中，以操作内存的方式操作磁盘，性能又提升了一个档次。

在 JAVA 中可通过 FileChannel 的 map 方法创建**内存映射文件**。

在 Linux 服务器中由该方法创建的文件使用的就是操作系统的 pagecache，即页缓存。

   Linux 操作系统中的内存使用策略时会尽可能地利用机器的物理内存，并常驻内存中，就是所谓的页缓存。在操作系统的内存不够的情况下，采用缓存置换算法，例如 LRU 将不常用的页缓存回收，即操作系统会自动管理这部分内存。

如果 RocketMQ Broker 进程异常退出，存储在页缓存中的数据并不会丢失，操作系统会定时将页缓存中的数据持久化到磁盘，做到数据安全可靠。不过如果是机器断电等异常情况，存储在页缓存中的数据就有可能丢失。

**问题**

   引入了内存映射和页缓存机制，消息会先写入到页缓存, 但是此时消息没有真正的同步到磁盘里面, broker 收到客户端的消息发送后，是存储到页缓存中就直接返回成功，还是要持久化到磁盘中才返回成功呢？

   这是一个“艰难”的抉择，是在性能与消息可靠性方面进行权衡。为此，RocketMQ 提供了多种策略：同步刷盘、异步刷盘。

#### 同步刷盘

同步刷盘在 RocketMQ 的实现中成为组提交，简单来说就是, 实现**批量消息刷盘**.

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644575659429.png)

采用同步刷盘，每一个线程将数据追到到内存后，并向刷盘线程提交刷盘请求，然后会阻塞；

刷盘线程从任务队列中获取一个任务，然后触发一次刷盘，但并不只刷与请求相关的消息，而是会直接将内存中待刷盘的所有消息一次批量刷盘，然后就可以唤醒一组请求线程，实现组刷盘。

#### 异步刷盘

如果能容忍一定几率的消息丢失，可以考虑使用异步刷盘。

异步刷盘指的是 broker 将消息存储到 pagecache 后就立即返回成功，然后开启一个异步线程定时执行 FileChannel 的 forece 方法，将内存中的数据定时刷写到磁盘，默认间隔为 500ms。

### 内存级读写分离

RocketMQ 为了降低 pagecache 的使用压力引入了 transientStorePoolEnable 机制，即内存级别的读写分离机制。

默认情况下 RocketMQ 将消息写入 pagecache，消息消费时从 pagecache 中读取，这样在高并发时 pagecache 的压力会比较大，容易出现瞬时 broker busy，

故 RocketMQ 还引入了 transientStorePoolEnable，将消息先写入堆外内存并立即返回，然后异步将堆外内存中的数据提交到 pagecache，再异步刷盘到磁盘中。其工作机制如下图所示：

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644576142348.png)

消息在消费读取时不会尝试从堆外内存中读，而是从 pagecache 中读取，这样就形成了内存级别的读写分离，即消息写入时主要面对堆外内存，而读消息时主要面对 pagecache。

该方案的优点是消息是直接写入堆外内存，然后异步写入 pagecache。相比每条消息追加直接写入 pagechae，其最大的优势是将消息写入 pagecache 操作批量化。

该方案的缺点是如果由于某些意外操作导致 Broker 进程异常退出，那么存储在堆外内存的数据会丢失，但如果是放入 pagecache，broke r异常退出并不会丢失消息。

