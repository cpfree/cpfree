# 分布式下一致性hash算法

一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

## 传统hash算法

例如，有三台Redis，对于每次的访问都可以通过计算hash来求得hash值。
   如公式 h=hash(key)%3，我们把Redis编号设置成0,1,2来保存对应hash计算出来的值，h的值等于Redis对应的编号。

但是如果一个机器dump, 要将宕机的服务器从编号列表中移除, 相当于key需要重新计算.

正如一个hash表, `hash(key)`不变, 表大小变了, 也就是求模基数变了, 求模后落在的hash表位置也变了.

## 一致性hash算法

> 参考自: <https://segmentfault.com/a/1190000017847097>

简单的说，一致性哈希是将整个哈希值空间组织成一个虚拟的圆环

接下来，把服务器按照IP或主机名作为关键字进行哈希，这样就能确定其在哈希环的位置。

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644412789178.png)

然后，我们就可以使用哈希函数H计算值为key的数据在哈希环的具体位置h，根据h确定在环中的具体位置，从此位置沿顺时针滚动，遇到的第一台服务器就是其应该定位到的服务器。

例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下

![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644412823376.png)
根据一致性哈希算法，数据A会被定为到Server 1上，数据B被定为到Server 2上，而C、D被定为到Server 3上。

接下来考虑传统hash下的几个问题

1. 容错性

   假如RedisService2宕机, 那么数据B对应的节点保存到RedisService3中。因此，其中一台宕机后，干扰的只有前面的数据（原数据被保存到顺时针的下一个服务器），而不会干扰到其他的数据。

2. 扩展性

   假如增加一台服务器Redis4, 原本数据C是保存到Redis3中，但由于增加了Redis4，数据C被保存到Redis4中。干扰的也只有Redis3而已，其他数据不会受到影响。

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644412996000.png)

   因此，一致性哈希算法对于节点的增减都只需重定位换空间的一小部分即可，具有较好的容错性和可扩展性

**虚拟节点**

   前面部分都是讲述到Redis节点较多和节点分布较为均衡的情况，如果节点较少就会出现节点分布不均衡造成数据倾斜问题。

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644413093695.png)

   为了解决这种数据存储不平衡的问题，一致性哈希算法引入了虚拟节点机制，即对每个节点计算多个哈希值，每个计算结果位置都放置在对应节点中，这些节点称为虚拟节点。

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644413046740.png)

   例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为 RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3，具体位置如下图所示：

   对于数据定位的hash算法仍然不变，只是增加了虚拟节点到实际节点的映射。例如，数据C保存到虚拟节点Redis1#2，实际上数据保存到Redis1中。这样，就能解决服务节点少时数据不平均的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。


### 循环雪崩

1. 集群有ABC三台机器，机器A没能抵挡住洪荒之力，宕机了

2. 大部分流量打到B上, B也宕机了, 之后又打到C上, C也宕机了.

3. 然后三台都挂了

解决方式是, 在网关层进行限流, 熔断, 降级, 认真的配置一下节点数量与服务器, 做好压力测试.
