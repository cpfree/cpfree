---
keys: 
type: copy,blog,trim
url: <>
id: 220207-172434
---

# 哈希表

## 基本概念

1. hash表
   数组就是一个hash表

2. hash算法

   对一个值或对象进行计算, 计算结果映射到hash表上

3. hash碰撞

   多个对象通过hash算法映射到了hash表上面的同一个位置

### hash碰撞解决方式

hash碰撞一般会使用拉链法和线性探测法

> 如下面示例, 数据规模是 dataSize， 哈希表的大小为 tableSize

1. 拉链法
   
   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/20210823224335.png)

   > 要选择适当的哈希表的大小，这样既不会因为数组空值而浪费大量内存，也不会因为链表太长而在查找上浪费太多时间。
   >
   > 在java里面的`HashMap`结构中, 如果链表过长(超过8个),会将链表转换为红黑树的结构 

2. 线性探测法

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/20210823224455.png)

   > 使用线性探测法，一定要保证tableSize大于dataSize。我们需要依靠哈希表中的空位来解决碰撞问题。
   >
   > 例如冲突的位置，放了小李，那么就向下找一个空位放置小王的信息。所以要求tableSize一定要大于dataSize ，要不然哈希表上就没有空置的位置来存放 冲突的数据了。

3. 再哈希法：即发生冲突时，由其他的函数再计算一次哈希值。

4. 建立公共溢出区：将哈希表分为基本表和溢出表，发生冲突时，将冲突的元素放入溢出表。

### java 中的hash表

1. hashtable

   HashTable 默认的初始大小为 11, 每次扩容为原来的`两倍+1`

   哈希表的大小为素数时，简单的取模哈希的结果会更加均匀, 但是将容量扩容为一个素数, 性能耗损比较高, 因此扩容为 `2n+1`, 就可以了.
   HashTable 默认的初始大小为 11(素数), 扩容一次变23(素数), 再扩容变47(素数), 再扩容95(5*19, 虽然不是素数但是问题不大), 再扩容191(素数),再扩容383(素数),再扩容767(13*59),


为何 HashTable 每次扩容为原来的`2n+1`, hashMap 每次扩容为原来的两倍


首先简单几句话说下 hash 表的一些知识.

hash 表的简单实现就是一个数组, 数据实体或者是对象实体存入hash表的时候, 先对这个hash表进行简单的编码计算, 计算出一个数组下标, 将元素存到对应下标的数组里面.

因为hash表如此的结构, 因此会产生两个问题

   - `hash碰撞`(又称hash冲突)
   - 扩容

> - HashTable: JDK1.0 就有
> - HashMap: JDK1.2 出现

HashTable 和 HashMap 都是 hash 表的实现方式.

## 问题1: 为何HashTable 初始长度为何是11, 每次扩容为 `2n+1`倍

> 首先严重声明, 这或许是个错误答案.

假定hash函数计算出来的数值是比较均匀离散的, 那么对于hash表来说, hashcode 和 hash表大小`互质`是比较必要的, 可以使得对hash表大小取模的时候, 使下标结果变得比较均匀.

那么该怎么使两者进行互质呢?

   - 首先, 若是哈希表的大小为`质数`时, 那肯定是互质的, 但是扩容的时候难道还要计算下是否为`质数`吗? 为了性能, 使用奇数就是一个不错的选择.

   - 其次, 由于java里面hashCode是一个int整型数据, int整型数据是2的31次方, 也就是说只有2一个因数, 也即是说和`2`进行互质是非常必要的.

综上两点来看, `2n + 1` 就非常不错, 既保证是个奇数, 又一定和2进行互质, 同时容量扩充为原来的两倍, 大小比较合适.

HashTable 扩容就是这种实现方式. 

此外HashTable 默认的初始大小为 11, 这个11也不是随随便便取的一个.

   - 初始大小是 11, 素数.
   - 扩容一次变 23, 素数.
   - 再扩容下变 47, 素数.
   - 再扩容下变 95, 不是素数, 但是 95=5*19, 也是可以分得挺均匀的, 虽然不是素数但是问题不大.
   - 再扩容下变 191, 素数.
   - 再扩容下变 383, 素数.
   - 再扩容下变 767, 不是素数, 但是 767=13*59, 也是可以分得挺均匀的, 虽然不是素数但是问题不大.
   - 再扩容下变 1535, 不是素数, 但是 1535=307*5, 也是可以分得挺均匀的, 虽然不是素数但是问题不大.
   - 再扩容下变 3071, 不是素数, 但是 3071=83*37, 也是可以分得挺均匀的, 虽然不是素数但是问题不大.
   - 再扩容下变 6143, 素数.
   - ....

   如上, 11算是一个比较好的解决方案, 真要是选7, 13, 或19, 那么第二次就不是素数了, 选5的话又太小了.

> 事实上java里面的hashCode不是非常均匀离散的, 因为hashCode要想实现非常均匀的离散, 成本肯定很高, 若hash表大小是个质数绝对是比较有优势的.

下面是 `HashTable` 部分源码

   ```java
   public class Hashtable {
      // 无关代码略

      private void addEntry(int hash, K key, V value, int index) {
         modCount++;

         Entry<?,?> tab[] = table;
         if (count >= threshold) {
               // Rehash the table if the threshold is exceeded
               rehash();

               tab = table;
               // 获取对象 hashCode
               hash = key.hashCode();
               index = (hash & 0x7FFFFFFF) % tab.length;
         }

         Entry<K,V> e = (Entry<K,V>) tab[index];
         tab[index] = new Entry<>(hash, key, value, e);
         count++;
      }
   }
   ```

可以看出添加元素时**直接获取对象的 hashCode();**, 之后使用hash表大小取模就得到了下标.

## 问题2: 为何HashMap 初始长度为何是16, 每次扩容为 2n 倍

如下HashMap对对象求取 hashCode 的源码, 方法注释已经说的很明白了.

   ```java
      /**
      * Computes key.hashCode() and spreads (XORs) higher bits of hash
      * to lower.  Because the table uses power-of-two masking, sets of
      * hashes that vary only in bits above the current mask will
      * always collide. (Among known examples are sets of Float keys
      * holding consecutive whole numbers in small tables.)  So we
      * apply a transform that spreads the impact of higher bits
      * downward. There is a tradeoff between speed, utility, and
      * quality of bit-spreading. Because many common sets of hashes
      * are already reasonably distributed (so don't benefit from
      * spreading), and because we use trees to handle large sets of
      * collisions in bins, we just XOR some shifted bits in the
      * cheapest possible way to reduce systematic lossage, as well as
      * to incorporate impact of the highest bits that would otherwise
      * never be used in index calculations because of table bounds.
      *
      * 计算 key.hashCode() 并将哈希的较高位传播（XOR）到较低位。 
      * 由于该表使用二次幂掩码，因此仅在当前掩码之上位变化的散列集将始终发生冲突。 
      *（已知的例子是在小表中保存连续整数的 Float 键集。）因此，我们应用了一种变换，
      * 将高位的影响向下传播。 在位扩展的速度、实用性和质量之间存在折衷。 
      * 因为许多常见的散列集已经合理分布（所以不要从传播中受益），
      * 并且因为我们使用树来处理 bin 中的大量冲突，
      * 我们只是以最便宜的方式对一些移位的位进行异或，以减少系统损失，
      * 以及合并最高位的影响，否则由于表边界，这些最高位将永远不会用于索引计算。
      */
      static final int hash(Object key) {
         int h;
         return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
      }
   ```

简单来说就是 HashMap 并没有像hashtable那样通过使用扩容 `2n+1` 的方式, 来保证让将对象哈希对数组大小取模的结果变得均匀.

而是获取对象`hashCode`(1个32位的int整型)之后, 通过将`高16位和原始hashCode进行异或`的方式使最终结果变得较为均匀.

也就是说, 经过高低位的二次离散, 仅仅这一步就可以折衷的将数据分的较为均匀了.

> 事实上, java里面的hashCode不是非常均匀离散的, 若是均匀离散的, 那么也就不需要高16位对低16位进行2次离散了.

这个分为几种情况

   1. hash表大小不是2的倍数, 那么此时对hash表大小取模需要用到 `%`, 且由于取模的特性, 会导致分配不是绝对均匀的.

   2. hash表大小是2的倍数, 那么此时取模实际上只需要和低位进行与运算即可, 因为高位一定是hash表大小的倍数, 所以高位数据会被整除, 导致实际上没有发生什么作用.

由于java里面的hashCode不是非常均匀离散的, 再加上传入的key计算成的hash值, 可能会导致在hash里面偏向一个地方.

虽然hashmap里面数组的大小最大可以达到Integer的最大值, 但是一般来说平时使用不会超过65535, 撑死用完低16位就不错了, 那么高16位岂不是浪费了.

> hashmap初始大小最大只能是 `2^30`, 但是可以最大扩容到 `2^31`

本着废物利用的原则, `高16位和原始hashCode进行异或` 一下, 可以对hashCode进行二次离散, 是一个不错的选择.

## 从设计角度分析HashMap的扩容设计

关于HashMap的扩容设计, 我们可以从设计的角度进行分析.

首先, HashTable 里面的`2n+1`扩容法, 虽然可以将hash表数据变得离散, 但是再扩容的时候也是很麻烦, 各种性能问题, 也就是HashTable是线程同步的, 在扩容的时候直接加🔒, 要是线程不安全的HashMap这样做的话, 那扩容的时候岂不是扩容时bug很容易就触发了.

那么设计人员肯定会想, 如果hashmap在扩容的时候, 扩容为原来的两倍, 而不是`2n+1`倍, 那么在扩容拷贝数据的时候就可以特别简单了, 首先`2n`肯定比`2n+1`更加**简单**, 而且`2n`还可以使用位运算, 更加**快速**.

如此选择扩容为 `2n` 就很有必要了.

---

这里简单科普一下

1. hash 分配不均匀问题

   首先假设`hashcode()`计算的值是均匀的, 也就是说假如`hashcode()`计算的值在0-n之间, 那么将所有数据计算一遍, 那么得到的值落在0-n范围内的数据应该是大致相等的.

   如果`hashcode()`计算的数居间在`[0, 20)`, 而hash数组大小是8, 将20个数字分配到`[0,8)`, `[0,4)` 里面每个分配3个值, 而 `[4,8)` 里面每个仅仅分配`2`个, 也就是说分配到 `[0,4)` 里面的值要比分配到 `[4,8)` 里面的要多`50%`, 这也就是hash分配不均匀的问题.

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644220168238.png)

2. 取模对hash分配的影响.

   从这个地方就可以看出, **HashTable里面的对可变长度的hash数组取模, 注定无法绝对做到均匀分配.**

   如果`hashcode()`计算的数居间在`[0, 100)`之间呢, 而hash数组大小是8, 那么将100个数字分配到`[0,8)`, `[0,4)` 里面每个分配13个值, 而 `[4,8)` 里面每个仅仅分配`12`个, 也就是说分配到 `[0,4)` 里面的值要比分配到 `[4,8)` 里面的要多`8.3%`.

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644220226896.png)

   从这个地方可以看出, `hashCode()`取值范围和hash表大小倍数差距越大, 那么分配均匀问题带来的差距越小.

   对于HashTable来说, `hashCode()`取值是一个整形int数据, 这个数非常大, 也就是**对于HashTable来说, 说取模带来的数据均匀问题影响非常小**

3. 绝对的均匀分配

   若是`hashcode()`计算的数居间在`[0, 40)`之间呢, 结果是40个数字均匀的分配到了`[0,8)`上.

   所以可以得到一个结论: **若`hashcode()`取值计算均匀, `hashcode()`计算的数若刚好是hash表大小倍数的话, 那么可以做到最均匀的数据离散**

   ![](https://gitee.com/cpfree/picture-warehouse/raw/master/pic1/1644220768352.png)

---
